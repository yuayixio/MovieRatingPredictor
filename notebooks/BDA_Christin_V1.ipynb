{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import all relevant packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Movie dataset</h2>\n",
    "Editing & cleaning OmDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/raw/movies.csv', sep=',')\n",
    "actors = pd.read_csv('../data/raw/actors.csv', sep=',')\n",
    "countries = pd.read_csv('../data/raw/countries.csv', sep=',')\n",
    "directors = pd.read_csv('../data/raw/directors.csv', sep=',')\n",
    "genres = pd.read_csv('../data/raw/genres.csv', sep=',')\n",
    "locations = pd.read_csv('../data/raw/locations.csv', sep=',')\n",
    "movie_tags = pd.read_csv('../data/raw/movie_tags.csv', sep=',')\n",
    "ratings = pd.read_csv('../data/raw/ratings.csv', sep=',')\n",
    "tags =  pd.read_csv('../data/raw/tags.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tags.rename(columns = {'id':'tagID'})\n",
    "tags_movies_merged = pd.merge(movie_tags, tags, how = 'outer', on = 'tagID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_movies_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_new = tags_movies_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[['id', 'title', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.rename(columns = {'id':'movieID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies = pd.merge(movies, tags_new, how = 'outer', on='movieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies = pd.merge(merged_movies, ratings, how='outer', on='movieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies.sort_values(by=['user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.array(merged_movies['year'], np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>OmDB</h2>\n",
    "\n",
    "Editing & cleaning OmDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read omdb_totoal.csv\n",
    "omdb = pd.read_csv('../data/raw/omdb_total.csv', sep=',')\n",
    "\n",
    "# delete unwanted columns\n",
    "omdb = omdb.drop(columns={'Unnamed: 0', 'Response'})\n",
    "# delete sparse or unimportant columns\n",
    "omdb = omdb.drop(columns={'Production', 'Website', 'totalSeasons', 'Season', 'Episode', 'seriesID', 'Type', 'BoxOffice', 'DVD', 'Poster'})\n",
    "# delete duplicate ratings\n",
    "omdb = omdb.drop(columns={'Internet Movie Database', 'Metacritic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming rotten tomatoes into float\n",
    "omdb['Rotten Tomatoes'] = omdb['Rotten Tomatoes'].str.replace(r'\\D', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define method in order to extract relevant trophies and nominations (Oscars, Golden Globes, Wins, Nominations)\n",
    "def awards(x):\n",
    "    \n",
    "    x['Oscars_won'] = np.NaN\n",
    "    x['Oscars_nominated'] = np.NaN\n",
    "    x['Globes_won'] = np.NaN\n",
    "    x['Globes_nominated'] = np.NaN  \n",
    "    x['Award_wins'] = np.NaN\n",
    "    x['Award_nominations'] = np.NaN  \n",
    "    \n",
    "    for index, row in x.iterrows():\n",
    "        y = row['Awards']\n",
    "        \n",
    "        nom = \"Nominated\"\n",
    "        won = \"Won\"\n",
    "    \n",
    "        oscar = \"Oscar\"\n",
    "        globes = \"Golden Globe\"\n",
    "        wins = \"win\"\n",
    "        nom2 = \"nomination\"\n",
    "        \n",
    "        if isinstance(y,str):\n",
    "            \n",
    "            if oscar in y:   \n",
    "                if y.startswith(won):\n",
    "                    x.at[index, 'Oscars_won'] = float(y[(y.find(oscar)-2):y.find(oscar)])\n",
    "                    x.at[index, 'Oscars_nominated'] = float(y[(y.find(oscar)-2):y.find(oscar)])\n",
    "                    \n",
    "                else:\n",
    "                    x.at[index, 'Oscars_won'] = 0.0\n",
    "                    x.at[index, 'Oscars_nominated'] = float(y[(y.find(oscar)-2):y.find(oscar)])\n",
    "            else: \n",
    "                x.at[index, 'Oscars_won'] = 0.0\n",
    "                x.at[index, 'Oscars_nominated'] = 0.0\n",
    "             \n",
    "            if globes in y:   \n",
    "                if y.startswith(won):\n",
    "                    x.at[index, 'Globes_won'] = float(y[(y.find(globes)-2):y.find(globes)])\n",
    "                    x.at[index, 'Globes_nominated'] = float(y[(y.find(globes)-2):y.find(globes)])\n",
    "                    \n",
    "                else:\n",
    "                    x.at[index, 'Globes_won'] = 0.0\n",
    "                    x.at[index, 'Globes_nominated'] = float(y[(y.find(globes)-2):y.find(globes)])\n",
    "            else: \n",
    "                x.at[index, 'Globes_won'] = 0.0\n",
    "                x.at[index, 'Globes_nominated'] = 0.0\n",
    "            \n",
    "            if wins in y:\n",
    "                try:\n",
    "                    x.at[index, 'Award_wins'] = float(y[(y.find(wins)-3):y.find(wins)])\n",
    "                except:\n",
    "                    x.at[index, 'Award_wins'] = float(y[(y.find(wins)-2):y.find(wins)])\n",
    "            else:\n",
    "                x.at[index, 'Award_wins'] = 0.0\n",
    "            if nom2 in y:\n",
    "                try:\n",
    "                    x.at[index, 'Award_nominations'] = float(y[(y.find(nom2)-3):y.find(nom2)])\n",
    "                except:\n",
    "                    x.at[index, 'Award_nominations'] = float(y[(y.find(nom2)-2):y.find(nom2)])\n",
    "            else:\n",
    "                x.at[index, 'Award_nominations'] = 0.0\n",
    "        else:\n",
    "            x.at[index, 'Oscars_won'] = 0.0\n",
    "            x.at[index, 'Oscars_nominated'] = 0.0\n",
    "            x.at[index, 'Globes_won'] = 0.0\n",
    "            x.at[index, 'Globes_nominated'] = 0.0\n",
    "            x.at[index, 'Award_wins'] = 0.0\n",
    "            x.at[index, 'Award_nominations'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply method and drop old column\n",
    "awards(omdb)\n",
    "omdb = omdb.drop(['Awards'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define method in order to know which genres the movies have (firstly find all categories and add a column for each unique value)\n",
    "#assign 1.0 if movie is in the genre, else assign 0.0\n",
    "def genre(x):\n",
    "    _set = set()\n",
    "    \n",
    "    for index, row in x.iterrows():\n",
    "        y = row['Genre']\n",
    "        if isinstance(y,str):\n",
    "            for i in y.split(','):\n",
    "                _set.add(i.strip())\n",
    "            ls = list(_set)\n",
    "            ls.sort()\n",
    "    for i in ls:\n",
    "        x[i] = 0.0\n",
    "    \n",
    "    for index, row in x.iterrows():\n",
    "        y = row['Genre']\n",
    "        if isinstance(y,str):\n",
    "            for i in y.split(','):\n",
    "                i = i.strip()\n",
    "                \n",
    "                if i == 'Action':\n",
    "                    x.at[index, 'Action'] = 1.0\n",
    "                if i == 'Adult':\n",
    "                    x.at[index, 'Adult'] = 1.0\n",
    "                if i == 'Adventure':\n",
    "                    x.at[index, 'Adventure'] = 1.0\n",
    "                if i == 'Animation':\n",
    "                    x.at[index, 'Animation'] = 1.0\n",
    "                if i == 'Biography':\n",
    "                    x.at[index, 'Biography'] = 1.0\n",
    "                if i == 'Comedy':\n",
    "                    x.at[index, 'Comedy'] = 1.0\n",
    "                if i == 'Documentary':\n",
    "                    x.at[index, 'Documentary'] = 1.0\n",
    "                if i == 'Drama':\n",
    "                    x.at[index, 'Drama'] = 1.0\n",
    "                if i == 'Family':\n",
    "                    x.at[index, 'Family'] = 1.0\n",
    "                if i == 'Fantasy':\n",
    "                    x.at[index, 'Fantasy'] = 1.0\n",
    "                if i == 'Crime':\n",
    "                    x.at[index, 'Crime'] = 1.0\n",
    "                if i == 'Film-Noir':\n",
    "                    x.at[index, 'Film-Noir'] = 1.0\n",
    "                if i == 'History':\n",
    "                    x.at[index, 'History'] = 1.0\n",
    "                if i == 'Horror':\n",
    "                    x.at[index, 'Horror'] = 1.0\n",
    "                if i == 'Music':\n",
    "                    x.at[index, 'Music'] = 1.0\n",
    "                if i == 'Musical':\n",
    "                    x.at[index, 'Musical'] = 1.0\n",
    "                if i == 'Mystery':\n",
    "                    x.at[index, 'Mystery'] = 1.0\n",
    "                if i == 'News':\n",
    "                    x.at[index, 'News'] = 1.0\n",
    "                if i == 'Reality-TV':\n",
    "                    x.at[index, 'Reality-TV'] = 1.0\n",
    "                if i == 'Romance':\n",
    "                    x.at[index, 'Romance'] = 1.0\n",
    "                if i == 'Sci-Fi':\n",
    "                    x.at[index, 'Sci-Fi'] = 1.0\n",
    "                if i == 'Short':\n",
    "                    x.at[index, 'Short'] = 1.0\n",
    "                if i == 'Sport':\n",
    "                    x.at[index, 'Sport'] = 1.0\n",
    "                if i == 'Talk-Show':\n",
    "                    x.at[index, 'Talk-Show'] = 1.0\n",
    "                if i == 'Thriller':\n",
    "                    x.at[index, 'Thriller'] = 1.0\n",
    "                if i == 'War':\n",
    "                    x.at[index, 'War'] = 1.0\n",
    "                if i == 'Western':\n",
    "                    x.at[index, 'Western'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply method and drop old column\n",
    "genre(omdb)\n",
    "omdb = omdb.drop(['Genre'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean typos and convert all parental-guideline ratings into a scale from 0 - 4 according to suitedness for children\n",
    "rated_dic = {'R': 3, 'PG-13': 2, 'PG': 1, 'Not Rated': np.NaN, 'nan': np.NaN, 'Approved': np.NaN, 'G': 0, 'Passed': np.NaN, 'Unrated': np.NaN, '14': 2, 'GP': 1, 'NC-17': 4, 'NOT RATED': np.NaN, 'APPROVED': np.NaN, 'MA': 4, 'UNRATED': np.NaN, 'PASSED': np.NaN, 'M': np.NaN, 'M/PG': np.NaN, 'X': np.NaN, 'Y7': 0}\n",
    "omdb['Rated'] = omdb['Rated'].astype(str).apply(lambda x: x.replace(\"TV-\",\"\")).replace(rated_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill all NaN values with average of each column as movie seems mediocre (not too bad to downvote, not too good to upvote)\n",
    "\n",
    "omdb['Metascore'].fillna((math.ceil(omdb['Metascore'].mean())), inplace=True)\n",
    "omdb['imdbRating'].fillna((math.ceil(omdb['imdbRating'].mean())), inplace=True)\n",
    "omdb['Rotten Tomatoes'].fillna((math.ceil(omdb['Rotten Tomatoes'].mean())), inplace=True)\n",
    "omdb['imdbVotes'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert release dates into seasons \n",
    "#(in order to compare spring(march,april,may)=2, summer(june,july,august)=3, fall(september,october,november=4 & winter=1)\n",
    "def dates(x):\n",
    "    omdb['Released'] = pd.to_datetime(omdb['Released'])\n",
    "    omdb['Released_season'] = np.NaN\n",
    "    omdb['Released_month'] = np.NaN\n",
    "    omdb['Released_day'] = np.NaN\n",
    "    \n",
    "    for index, row in x.iterrows():\n",
    "        y = row['Released']\n",
    "        x.at[index, 'Released_season'] = (y.month%12 + 3)//3\n",
    "        x.at[index, 'Released_month'] = y.month\n",
    "        x.at[index, 'Released_day'] = y.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates(omdb)\n",
    "omdb = omdb.drop(['Released'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming runtime into float\n",
    "omdb['Runtime'] = omdb['Runtime'].str[:-4].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform language attribute\n",
    "def language(x):\n",
    "    _set = set()\n",
    "    \n",
    "    for index, row in x.iterrows():\n",
    "        y = row['Language']\n",
    "        if isinstance(y,str):\n",
    "            for i in y.split(','):\n",
    "                _set.add(i.strip())\n",
    "            ls = list(_set)\n",
    "            ls.sort()\n",
    "    \n",
    "    _dict = {}  \n",
    "    for i in ls: \n",
    "        count=0\n",
    "        for index, row in x.iterrows():\n",
    "            y = row['Language']\n",
    "            if isinstance(y,str):    \n",
    "                if i in y:\n",
    "                    count = count+1\n",
    "                    _dict[i] = count\n",
    "                     \n",
    "    ls_ = sorted(_dict, key=_dict.get, reverse=True)[:5]        \n",
    "    \n",
    "    for i in ls_ :\n",
    "        omdb[i] = np.nan\n",
    "    \n",
    "    for i in ls_:\n",
    "        for index, row in x.iterrows():\n",
    "            y = row['Language']\n",
    "            if isinstance(y,str): \n",
    "                if i in y:\n",
    "                    x.at[index, i] = 1.0\n",
    "                else:\n",
    "                    x.at[index,i] = 0.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "['Aboriginal', 'Acholi', 'Afrikaans', 'Albanian', 'Algonquin', 'American Sign Language', 'Amharic', 'Ancient (to 1453)', 'Apache languages', 'Arabic', 'Aramaic', 'Arapaho', 'Armenian', 'Assamese', 'Assyrian Neo-Aramaic', 'Athapascan languages', 'Awadhi', 'Azerbaijani', 'Bambara', 'Belarusian', 'Bengali', 'Berber languages', 'Bosnian', 'Brazilian Sign Language', 'British Sign Language', 'Bulgarian', 'Burmese', 'Cantonese', 'Catalan', 'Central American Indian languages', 'Chechen', 'Cheyenne', 'Chinese', 'Cornish', 'Corsican', 'Cree', 'Croatian', 'Crow', 'Czech', 'Danish', 'Dari', 'Dutch', 'Dzongkha', 'Egyptian (Ancient)', 'English', 'Esperanto', 'Estonian', 'Ewe', 'Filipino', 'Finnish', 'Flemish', 'French', 'French Sign Language', 'Fur', 'Gallegan', 'Georgian', 'German', 'German Sign Language', 'Greek', 'Guarani', 'Hakka', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hokkien', 'Hopi', 'Hungarian', 'Icelandic', 'Indonesian', 'Inuktitut', 'Irish', 'Italian', 'Japanese', 'Japanese Sign Language', 'Karajá', 'Khmer', 'Kinyarwanda', 'Kirundi', 'Klingon', 'Korean', 'Korean Sign Language', 'Kuna', 'Kurdish', 'Ladakhi', 'Lao', 'Latin', 'Latvian', 'Lingala', 'Lithuanian', 'Low German', 'Luxembourgish', 'Macedonian', 'Malay', 'Malinka', 'Maltese', 'Mandarin', 'Maori', 'Mapudungun', 'Marshallese', 'Maya', 'Mende', 'Middle English', 'Min Nan', 'Mohawk', 'Mongolian', 'More', 'Nahuatl', 'Navajo', 'Neapolitan', 'Nepali', 'None', 'Norse', 'North American Indian', 'Norwegian', 'Occitan', 'Old', 'Old English', 'Papiamento', 'Pawnee', 'Persian', 'Polish', 'Polynesian', 'Portuguese', 'Punjabi', 'Pushto', 'Quechua', 'Quenya', 'Rajasthani', 'Romanian', 'Romany', 'Russian', 'Ryukyuan', 'Saami', 'Sanskrit', 'Scanian', 'Scottish Gaelic', 'Serbian', 'Serbo-Croatian', 'Shanghainese', 'Sicilian', 'Sindarin', 'Sinhalese', 'Sioux', 'Slovak', 'Somali', 'Spanish', 'Spanish Sign Language', 'Swahili', 'Swedish', 'Swiss German', 'Syriac', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Thai', 'Tibetan', 'Tok Pisin', 'Tonga', 'Turkish', 'Tuvinian', 'Tzotzil', 'Ukrainian', 'Ungwatsi', 'Urdu', 'Uzbek', 'Vietnamese', 'Washoe', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n"
     ]
    }
   ],
   "source": [
    "language(omdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Joining the data</h2>\n",
    "After joining the relevant data you can test different approaches in order to predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.merge(omdb, merged_movies, how='outer', on=['title','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(full_data.iloc[:,0:11])\n",
    "\n",
    "y = np.array(full_data['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(0,11):\n",
    "    X[:,i] = le.fit_transform(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
