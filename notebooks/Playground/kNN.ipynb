{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# set random state for reproducibility\n",
    "kwargs = dict(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "movies = pd.read_csv('../../data/preprocessed/movies_id_updated.csv', sep=',')\n",
    "actors = pd.read_csv('../../data/raw/actors.csv', sep=',')\n",
    "countries = pd.read_csv('../../data/raw/countries.csv', sep=',')\n",
    "directors = pd.read_csv('../../data/raw/directors.csv', sep=',')\n",
    "genres = pd.read_csv('../../data/raw/genres.csv', sep=',')\n",
    "locations = pd.read_csv('../../data/raw/locations.csv', sep=',')\n",
    "movie_tags = pd.read_csv('../../data/raw/movie_tags.csv', sep=',')\n",
    "ratings = pd.read_csv('../../data/raw/ratings.csv', sep=',')\n",
    "tags =  pd.read_csv('../../data/raw/tags.csv', sep=',')\n",
    "omdb = pd.read_csv('../../preprocessed/omdb_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging data like Christin -> created csv was 1,11GB \n",
    "movies = movies[['id', 'title', 'year']]\n",
    "movies = movies.rename(columns = {'id':'movieID'})\n",
    "actors.dropna()\n",
    "merged_movies = pd.merge(movies, actors, how = 'outer', on='movieID')\n",
    "countries.dropna()\n",
    "merged_movies = pd.merge(merged_movies, countries, how = 'outer', on='movieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors.dropna()\n",
    "merged_movies = pd.merge(merged_movies, directors, how = 'outer', on='movieID')\n",
    "genres.dropna()\n",
    "merged_movies = pd.merge(merged_movies, genres, how = 'outer', on='movieID')\n",
    "merged_movies = pd.merge(merged_movies, ratings, how='outer', on='movieID')\n",
    "merged_movies = merged_movies.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>actorID</th>\n",
       "      <th>actorName</th>\n",
       "      <th>ranking</th>\n",
       "      <th>country</th>\n",
       "      <th>directorID</th>\n",
       "      <th>directorName</th>\n",
       "      <th>genre</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>annie_potts</td>\n",
       "      <td>Annie Potts</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>john_lasseter</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>annie_potts</td>\n",
       "      <td>Annie Potts</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>john_lasseter</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>551.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>annie_potts</td>\n",
       "      <td>Annie Potts</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>john_lasseter</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>336.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>annie_potts</td>\n",
       "      <td>Annie Potts</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>john_lasseter</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>annie_potts</td>\n",
       "      <td>Annie Potts</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>john_lasseter</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59296576</th>\n",
       "      <td>65133</td>\n",
       "      <td>Blackadder Back &amp; Forth</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>tim_mcinnerny</td>\n",
       "      <td>Tim McInnerny</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>paul_weiland</td>\n",
       "      <td>Paul Weiland</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59296577</th>\n",
       "      <td>65133</td>\n",
       "      <td>Blackadder Back &amp; Forth</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>tim_mcinnerny</td>\n",
       "      <td>Tim McInnerny</td>\n",
       "      <td>9.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>paul_weiland</td>\n",
       "      <td>Paul Weiland</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59296578</th>\n",
       "      <td>65133</td>\n",
       "      <td>Blackadder Back &amp; Forth</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>tony_robinson</td>\n",
       "      <td>Tony Robinson</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>paul_weiland</td>\n",
       "      <td>Paul Weiland</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59296579</th>\n",
       "      <td>65133</td>\n",
       "      <td>Blackadder Back &amp; Forth</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>tony_robinson</td>\n",
       "      <td>Tony Robinson</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>paul_weiland</td>\n",
       "      <td>Paul Weiland</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59296580</th>\n",
       "      <td>65133</td>\n",
       "      <td>Blackadder Back &amp; Forth</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>tony_robinson</td>\n",
       "      <td>Tony Robinson</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>paul_weiland</td>\n",
       "      <td>Paul Weiland</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59201622 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movieID                    title    year        actorID  \\\n",
       "0               1                Toy story  1995.0    annie_potts   \n",
       "1               1                Toy story  1995.0    annie_potts   \n",
       "2               1                Toy story  1995.0    annie_potts   \n",
       "3               1                Toy story  1995.0    annie_potts   \n",
       "4               1                Toy story  1995.0    annie_potts   \n",
       "...           ...                      ...     ...            ...   \n",
       "59296576    65133  Blackadder Back & Forth  1999.0  tim_mcinnerny   \n",
       "59296577    65133  Blackadder Back & Forth  1999.0  tim_mcinnerny   \n",
       "59296578    65133  Blackadder Back & Forth  1999.0  tony_robinson   \n",
       "59296579    65133  Blackadder Back & Forth  1999.0  tony_robinson   \n",
       "59296580    65133  Blackadder Back & Forth  1999.0  tony_robinson   \n",
       "\n",
       "              actorName  ranking country     directorID   directorName  \\\n",
       "0           Annie Potts     10.0     USA  john_lasseter  John Lasseter   \n",
       "1           Annie Potts     10.0     USA  john_lasseter  John Lasseter   \n",
       "2           Annie Potts     10.0     USA  john_lasseter  John Lasseter   \n",
       "3           Annie Potts     10.0     USA  john_lasseter  John Lasseter   \n",
       "4           Annie Potts     10.0     USA  john_lasseter  John Lasseter   \n",
       "...                 ...      ...     ...            ...            ...   \n",
       "59296576  Tim McInnerny      9.0      UK   paul_weiland   Paul Weiland   \n",
       "59296577  Tim McInnerny      9.0      UK   paul_weiland   Paul Weiland   \n",
       "59296578  Tony Robinson     10.0      UK   paul_weiland   Paul Weiland   \n",
       "59296579  Tony Robinson     10.0      UK   paul_weiland   Paul Weiland   \n",
       "59296580  Tony Robinson     10.0      UK   paul_weiland   Paul Weiland   \n",
       "\n",
       "              genre  user_id  rating  \n",
       "0         Adventure   1339.0     5.0  \n",
       "1         Adventure    551.0     3.5  \n",
       "2         Adventure    336.0     4.5  \n",
       "3         Adventure   1087.0     3.5  \n",
       "4         Adventure   1598.0     4.0  \n",
       "...             ...      ...     ...  \n",
       "59296576     Comedy    480.0     5.0  \n",
       "59296577     Comedy   1228.0     3.0  \n",
       "59296578     Comedy   1059.0     4.0  \n",
       "59296579     Comedy    480.0     5.0  \n",
       "59296580     Comedy   1228.0     3.0  \n",
       "\n",
       "[59201622 rows x 12 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricted to X Rows currently for faster calculations (r)\n",
    "merged_movies = merged_movies.iloc[:100000]\n",
    "\n",
    "X = np.array(merged_movies.iloc[:,0:11])\n",
    "\n",
    "y = np.array(merged_movies['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 11)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "# Checking Array dimensions\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data: Remove all Strings\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(0,11):\n",
    "    X[:,i] = le.fit_transform(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test set\n",
    "#TODO Split Data in Three and optimize for validation set to compare rmse and accuracy for Validation and Test Set!\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/5, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Classifier until k=10\n",
      "Tested Classifier until k=20\n",
      "Tested Classifier until k=30\n",
      "Tested Classifier until k=40\n",
      "Tested Classifier until k=50\n",
      "Tested Classifier until k=60\n",
      "Tested Classifier until k=70\n",
      "Tested Classifier until k=80\n",
      "Tested Classifier until k=90\n",
      "Tested Classifier until k=100\n",
      "Tested Classifier until k=110\n",
      "Tested Classifier until k=120\n",
      "Tested Classifier until k=130\n",
      "Tested Classifier until k=140\n",
      "Tested Classifier until k=150\n",
      "Tested Classifier until k=160\n",
      "Tested Classifier until k=170\n",
      "Tested Classifier until k=180\n",
      "Tested Classifier until k=190\n",
      "Optmial k: 3\n"
     ]
    }
   ],
   "source": [
    "# Define Classifier \n",
    "#Adjust k neighbors value according to dataset \n",
    "#May take a while depending on how large the dataset is chosen above -> r\n",
    "optimal_k = find_optimal_k()\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=3)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training Classifier\n",
    "print(\"Training\")\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do Prediction\n"
     ]
    }
   ],
   "source": [
    "# Do predictions\n",
    "print(\"Do Prediction\")\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.60805\n",
      "RMSE : 1.7691240770505612\n"
     ]
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "print(\"Accuracy : {}\".format(accuracy_score(y_test, pred)))\n",
    "#RMSE for ratings [0,5]\n",
    "print(\"RMSE : {}\".format(mean_squared_error(y_test, pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improve Algorithm and find good k to choose\n",
    "#Limit data set to X rows for finding optimal k\n",
    "#!Only execute this cell for full dataset with time and computational power!\n",
    "\n",
    "#Lets save time for now\n",
    "limited_movies = merged_movies.iloc[:100000]\n",
    "\n",
    "X = np.array(limited_movies.iloc[:,0:5])\n",
    "\n",
    "y = np.array(limited_movies['rating'])\n",
    "\n",
    "def find_optimal_k():\n",
    "    k_acc_scores = []\n",
    "    accuracy = 0\n",
    "    \n",
    "    for k in range(1, 200):\n",
    "        if k % 10 == 0 :\n",
    "            print(\"Tested Classifier until k=\"+str(k))\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=k,n_jobs=-1)\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        k_acc_scores.append(\"k({}) = Accuracy: {} RMSE: {} \".format(k, accuracy_score(y_test, pred), mean_squared_error(y_test, pred, squared=False)))\n",
    "        \n",
    "        if (accuracy_score(y_test, pred) > accuracy):\n",
    "            optimal_k = k\n",
    "            accuracy = accuracy_score(y_test, pred)\n",
    "   \n",
    "    #For full info\n",
    "    #print(k_acc_scores)\n",
    "    \n",
    "    print(\"Optmial k: \"+str(optimal_k)+\"with accuracy: \"+str(accuracy))\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN rows - check later if it makes large difference!\n",
    "omdb=omdb.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9938421e-01, 3.9600000e-04, 2.0314000e-04, 1.6650000e-05,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform principal components analysis on training set\n",
    "pca = PCA(**kwargs)\n",
    "pca.fit(X_train)\n",
    "pca.explained_variance_ratio_.round(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_trans = pca.transform(X_train)[:, :2]\n",
    "X_test_trans = pca.transform(X_test)[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2, n_jobs=-1)\n",
    "print(\"Training\")\n",
    "knn.fit(X_train_trans, y_train)\n",
    "print(\"Do Prediction\")\n",
    "pred = knn.predict(X_test_trans)\n",
    "# Check Accuracy\n",
    "print(\"Accuracy : {}\".format(accuracy_score(y_test, pred)))\n",
    "#RMSE for ratings [0,5]\n",
    "print(\"RMSE : {}\".format(mean_squared_error(y_test, pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Ansatzidee: \n",
    "#1 Seperate labeled and unlabeled data\n",
    "#2 Use SVM and SSL to train and improve  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ansatzidee: \n",
    "#1 Seperate labeled and unlabeled data\n",
    "#2 Use SVM and SSL to train and improve  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Do Prediction\n",
      "Accuracy : 0.9942\n",
      "RMSE : 0.20506096654409878\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2, n_jobs=-1)\n",
    "print(\"Training\")\n",
    "knn.fit(X_train_trans, y_train)\n",
    "print(\"Do Prediction\")\n",
    "pred = knn.predict(X_test_trans)\n",
    "# Check Accuracy\n",
    "print(\"Accuracy : {}\".format(accuracy_score(y_test, pred)))\n",
    "#RMSE for ratings [0,5]\n",
    "print(\"RMSE : {}\".format(mean_squared_error(y_test, pred, squared=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda-analytics-challenge-ss2020",
   "language": "python",
   "name": "bda-analytics-challenge-ss2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
